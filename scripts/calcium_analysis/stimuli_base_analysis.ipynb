{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6ec893369314bcfa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T15:04:35.881238Z",
     "start_time": "2025-11-21T15:04:35.016105Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.lines import Line2D\n",
    "from skimage.filters import threshold_otsu\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import src.stimuli_timeline as st\n",
    "import src.plotting as plott\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output_scroll {height: 500px; overflow-y: scroll;}</style>\"))\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('axes.spines', bottom=True, left=True, right=False, top=False)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.output_scroll {height: 500px; overflow-y: scroll;}</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:04:39.730375Z",
     "start_time": "2025-11-21T15:04:38.624017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage.filters import threshold_otsu\n",
    "import src.stimuli_timeline as st\n",
    "import src.plotting as plott\n",
    "import src.data_loading as exio   # ðŸ‘ˆ instead of: from src.experiment_io import load_2p_experiment\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('axes.spines', bottom=True, left=True, right=False, top=False)\n",
    "\n"
   ],
   "id": "7bba2129ff9651bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:04:42.102284Z",
     "start_time": "2025-11-21T15:04:41.765873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== CONFIG ================================================================\n",
    "fish_id = \"L433_f02\"\n",
    "experiment_name = \"Exp_1_flickering\"\n",
    "\n",
    "main_path = Path(r\"C:\\Users\\suribear\\OneDrive - UniversitÃ© de Lausanne\\Lab\\Data\\2p\")\n",
    "stimuli_main_path = Path(r\"\\\\nasdcsr.unil.ch\\RECHERCHE\\FAC\\FBM\\CIG\\jlarsch\\default\\D2c\\Alejandro\\2p\")\n",
    "\n",
    "fps_2p = 2.0\n",
    "selected_blocks = [f\"B{n}\" for n in range(1, 3)]\n",
    "\n",
    "# ==== LOAD EVERYTHING IN ONE GO ============================================\n",
    "results = exio.load_2p_experiment(\n",
    "    fish_id=fish_id,\n",
    "    experiment_name=experiment_name,\n",
    "    main_path=main_path,\n",
    "    stimuli_main_path=stimuli_main_path,\n",
    "    fps_2p=fps_2p,\n",
    "    selected_blocks=selected_blocks,\n",
    ")\n",
    "\n",
    "dfof              = results[\"dfof\"]\n",
    "stimuli_durations = results[\"stimuli_durations\"]\n",
    "adjusted_log      = results[\"adjusted_log\"]\n",
    "stimuli_trace_60  = results[\"stimuli_trace_60\"]\n",
    "stimuli_table     = results[\"stimuli_table\"]\n",
    "stimuli_id_map    = results[\"stimuli_id_map\"]\n",
    "duration_2p_block_sec = results[\"duration_2p_block_sec\"]\n",
    "frames_per_block       = results[\"frames_per_block\"]\n",
    "paths                  = results[\"paths\"]\n",
    "\n",
    "print(\"dFoF shape:\", dfof.shape)\n",
    "print(\"Frames per block:\", frames_per_block)\n",
    "print(\"Paths:\", paths[\"dfof_file\"])"
   ],
   "id": "51e51f3a7b89148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using preferred dFoF file: C:\\Users\\suribear\\OneDrive - UniversitÃ© de Lausanne\\Lab\\Data\\2p\\L433_f02_Exp_1_flickering\\03_analysis\\functional\\suite2P\\merged_dFoF\\L433_f02_dFoF_merged.npy\n",
      "âœ… Using block log: C:\\Users\\suribear\\OneDrive - UniversitÃ© de Lausanne\\Lab\\Data\\2p\\L433_f02_Exp_1_flickering\\01_raw\\2p\\metadata\\2025-08-05-1506_L433_f02_block_log.csv\n",
      "dFoF shape: (3340, 1984)\n",
      "Frames per block: 1670\n",
      "Paths: C:\\Users\\suribear\\OneDrive - UniversitÃ© de Lausanne\\Lab\\Data\\2p\\L433_f02_Exp_1_flickering\\03_analysis\\functional\\suite2P\\merged_dFoF\\L433_f02_dFoF_merged.npy\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:04:44.957836Z",
     "start_time": "2025-11-21T15:04:44.823324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Transform 60 hrs stimuli trace to 2 Hz to match cell traces\n",
    "cell_traces=dfof.T # shape (n_neurons, T)\n",
    "n_neurons, T = cell_traces.shape\n",
    "t_2p_sec = np.arange(T) / float(fps_2p)        # [0, 0.5, 1.0, ..., 1669.5] seconds\n",
    "idx60 = np.floor(t_2p_sec * 60.0).astype(int)     # map to 60 Hz indices\n",
    "idx60 = np.clip(idx60, 0, len(stimuli_trace_60) - 1)  # clamp to valid range\n",
    "stimuli_trace = stimuli_trace_60[idx60]\n",
    "\n",
    "# define analysis window around stimulus onset\n",
    "# peri-stimulus window in seconds\n",
    "\n",
    "t_pre_s  = 5.0   # time before onset to include\n",
    "t_post_s = 29.0  # time after onset to include\n",
    "\n",
    "# convert to frames\n",
    "pre_frames  = int(round(t_pre_s * fps_2p))\n",
    "post_frames = int(round(t_post_s * fps_2p))\n",
    "win_lenght = pre_frames + post_frames\n",
    "\n",
    "# list which stimulus IDs are present in the trace (excluding 0)\n",
    "# stimuli traces is a vector of 0 when there is no stimulus, and >0 for stimulus IDs, is already in 2 hrz matching with cell_traces means (2 Hz)\n",
    "\n",
    "stimuli_ids = sorted(int(x) for x in np.unique(stimuli_trace) if x != 0)\n",
    "stimuli_names = list(stimuli_id_map.keys())\n",
    "\n",
    "# sanity checks\n",
    "assert cell_traces.ndim == 2, \"traces must be (n_neurons, T)\"\n",
    "assert stimuli_trace.ndim == 1, \"stim_trace must be (T,)\"\n",
    "assert cell_traces.shape[1] == stimuli_trace.shape[0], \"time dimension mismatch\"\n",
    "\n",
    "print(f\"Number of neurons: {n_neurons}\")\n",
    "print(f\"Number of time points: {T}\")\n",
    "print(\"2p duration (s):\", T/ fps_2p)               # 1670.0\n",
    "print(\"60Hz duration from data (s):\", len(stimuli_trace_60) / 60.0)  # ~1665.64\n",
    "print(\"Output shape:\", stimuli_trace.shape)\n",
    "\n",
    "# take traces when the stimuli are presented, and some frames before and after\n",
    "onsets_by_id = {}\n",
    "trial_aligned_traces = {}   # sid -> (n_neurons, win_lenght, n_trials)\n",
    "# n_trials_by_id = {}\n",
    "# dropped_onsets_by_id = {}\n",
    "\n",
    "for stim in stimuli_ids:\n",
    "    # find onsets frames (0â†’1 transitions)\n",
    "    active = (stimuli_trace == stim).astype(np.int8)\n",
    "    transitions = np.diff(active, prepend=0)\n",
    "    onsets = np.flatnonzero(transitions == 1)\n",
    "    onsets_by_id[stim] = onsets\n",
    "\n",
    "    # create windows and slices neuron trace to generate\n",
    "    starts = onsets - pre_frames\n",
    "    ends   = onsets + post_frames\n",
    "    keep   = (starts >= 0) & (ends <= T)\n",
    "\n",
    "    # arr is trial-aligned neural activity windows for each stimulus\n",
    "    # arr shape: (n_neurons, win_length, n_trials)\n",
    "    if not np.any(keep):\n",
    "        arr = np.empty((n_neurons, win_lenght, 0), dtype=float)\n",
    "    else:\n",
    "        arr = np.stack([cell_traces[:, s:e] for s, e in zip(starts[keep], ends[keep])], axis=2)\n",
    "\n",
    "    trial_aligned_traces[stim] = arr # store the aligned traces # neuron x time x trials per stimulus\n",
    "\n",
    "     # print summary\n",
    "\n",
    "    print(f\"stim {stim}: {onsets.size} onsets | kept {arr.shape[2]} trials | dropped {np.count_nonzero(~keep)}\")# (3340,)\n"
   ],
   "id": "26b464e0f6947b8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons: 1984\n",
      "Number of time points: 3340\n",
      "2p duration (s): 1670.0\n",
      "60Hz duration from data (s): 1665.6333333333334\n",
      "Output shape: (3340,)\n",
      "stim 1: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 2: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 3: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 4: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 5: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 6: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 7: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 8: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 9: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 10: 4 onsets | kept 4 trials | dropped 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:36:00.709835Z",
     "start_time": "2025-11-21T14:36:00.590111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_trial_aligned_traces(\n",
    "    dfof,\n",
    "    stimuli_trace_60,\n",
    "    fps_2p,\n",
    "    t_pre_s=5.0,\n",
    "    t_post_s=29.0,\n",
    "    stimuli_id_map=None,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build trial-aligned neural activity windows for each stimulus ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfof : array, shape (T, n_neurons) or (n_neurons, T) depending on how you store it\n",
    "        Î”F/F traces. In this function we assume dfof is (T, n_neurons)\n",
    "        and we transpose it to (n_neurons, T), like in your original code.\n",
    "    stimuli_trace_60 : array, shape (T_60,)\n",
    "        Stimulus trace sampled at 60 Hz. Values: 0 (no stim) or integer IDs.\n",
    "    fps_2p : float\n",
    "        Frame rate of 2P imaging (Hz).\n",
    "    t_pre_s : float\n",
    "        Seconds before onset to include in each window.\n",
    "    t_post_s : float\n",
    "        Seconds after onset to include in each window.\n",
    "    stimuli_id_map : dict, optional\n",
    "        Mapping from stimulus name -> ID. If provided, used to generate stimuli_names.\n",
    "        Otherwise stimuli_names will be ['stim_<id>', ...]\n",
    "    verbose : bool\n",
    "        If True, print sanity checks and per-stim summaries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            'cell_traces'        : (n_neurons, T) array\n",
    "            'stimuli_trace'      : (T,) array, 2P-matched stimulus IDs\n",
    "            'stimuli_ids'        : list of int\n",
    "            'stimuli_names'      : list of str\n",
    "            'trial_aligned_traces': dict {stim_id -> (n_neurons, win_length, n_trials)}\n",
    "            'onsets_by_id'       : dict {stim_id -> onsets (frames), n_trials }\n",
    "            'pre_frames'         : int\n",
    "            'post_frames'        : int\n",
    "            'win_length'         : int\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Match stimulus trace (60 Hz) to 2P sampling ---\n",
    "    # Assume your original convention: dfof shape (T, n_neurons)\n",
    "    cell_traces = dfof.T  # -> (n_neurons, T)\n",
    "    n_neurons, T = cell_traces.shape\n",
    "\n",
    "    t_2p_sec = np.arange(T) / float(fps_2p)         # time vector at 2P rate\n",
    "    idx60 = np.floor(t_2p_sec * 60.0).astype(int)  # map each 2P frame to 60 Hz index\n",
    "    idx60 = np.clip(idx60, 0, len(stimuli_trace_60) - 1)\n",
    "    stimuli_trace = stimuli_trace_60[idx60]\n",
    "\n",
    "    # --- 2) Define peri-stimulus window (in frames) ---\n",
    "    pre_frames  = int(round(t_pre_s  * fps_2p))\n",
    "    post_frames = int(round(t_post_s * fps_2p))\n",
    "    win_length  = pre_frames + post_frames\n",
    "\n",
    "    # --- 3) Stimulus IDs and names ---\n",
    "    stimuli_ids = sorted(int(x) for x in np.unique(stimuli_trace) if x != 0)\n",
    "\n",
    "    if stimuli_id_map is not None:\n",
    "        # user provided mapping name -> id; invert to get id -> name\n",
    "        id_to_name = {v: k for k, v in stimuli_id_map.items()}\n",
    "        stimuli_names = [id_to_name.get(sid, f\"stim_{sid}\") for sid in stimuli_ids]\n",
    "    else:\n",
    "        stimuli_names = [f\"stim_{sid}\" for sid in stimuli_ids]\n",
    "\n",
    "    # --- 4) Sanity checks ---\n",
    "    assert cell_traces.ndim == 2, \"traces must be (n_neurons, T)\"\n",
    "    assert stimuli_trace.ndim == 1, \"stimuli_trace must be (T,)\"\n",
    "    assert cell_traces.shape[1] == stimuli_trace.shape[0], \"time dimension mismatch\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Number of neurons: {n_neurons}\")\n",
    "        print(f\"Number of time points: {T}\")\n",
    "        print(\"2p duration (s):\", T / fps_2p)\n",
    "        print(\"60Hz duration from data (s):\", len(stimuli_trace_60) / 60.0)\n",
    "        print(\"Output stim trace shape:\", stimuli_trace.shape)\n",
    "        print(\"Stimuli IDs:\", stimuli_ids)\n",
    "        print(\"Stimuli names:\", stimuli_names)\n",
    "\n",
    "    # --- 5) Build trial-aligned traces per stimulus ---\n",
    "    onsets_by_id = {}\n",
    "    trial_aligned_traces = {}  # sid -> (n_neurons, win_length, n_trials)\n",
    "\n",
    "    for stim in stimuli_ids:\n",
    "        # 0â†’1 transitions: find onsets in the 2P-matched stimulus trace\n",
    "        active = (stimuli_trace == stim).astype(np.int8)\n",
    "        transitions = np.diff(active, prepend=0)\n",
    "        onsets = np.flatnonzero(transitions == 1)\n",
    "        onsets_by_id[stim] = onsets\n",
    "\n",
    "        starts = onsets - pre_frames\n",
    "        ends   = onsets + post_frames\n",
    "        keep   = (starts >= 0) & (ends <= T)\n",
    "\n",
    "        if not np.any(keep):\n",
    "            arr = np.empty((n_neurons, win_length, 0), dtype=float)\n",
    "        else:\n",
    "            arr = np.stack(\n",
    "                [cell_traces[:, s:e] for s, e in zip(starts[keep], ends[keep])],\n",
    "                axis=2\n",
    "            )\n",
    "\n",
    "        trial_aligned_traces[stim] = arr\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"stim {stim}: {onsets.size} onsets | \"\n",
    "                f\"kept {arr.shape[2]} trials | \"\n",
    "                f\"dropped {np.count_nonzero(~keep)}\"\n",
    "            )\n",
    "\n",
    "    # --- 6) Pack everything in a dict ---\n",
    "    result = {\n",
    "        \"cell_traces\": cell_traces,\n",
    "        \"stimuli_trace\": stimuli_trace,\n",
    "        \"stimuli_ids\": stimuli_ids,\n",
    "        \"stimuli_names\": stimuli_names,\n",
    "        \"trial_aligned_traces\": trial_aligned_traces,\n",
    "        \"onsets_by_id\": onsets_by_id,\n",
    "        \"pre_frames\": pre_frames,\n",
    "        \"post_frames\": post_frames,\n",
    "        \"win_length\": win_length,\n",
    "    }\n",
    "\n",
    "    return result\n"
   ],
   "id": "4a4c5ef37d6f6d83",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:36:08.952890Z",
     "start_time": "2025-11-21T14:36:08.820050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = build_trial_aligned_traces(\n",
    "    dfof=dfof,\n",
    "    stimuli_trace_60=stimuli_trace_60,\n",
    "    fps_2p=fps_2p,\n",
    "    t_pre_s=5.0,\n",
    "    t_post_s=29.0,\n",
    "    stimuli_id_map=stimuli_id_map,  # or None\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "trial_aligned_traces = res[\"trial_aligned_traces\"]\n",
    "stimuli_ids          = res[\"stimuli_ids\"]\n",
    "stimuli_names        = res[\"stimuli_names\"]\n",
    "win_length           = res[\"win_length\"]\n",
    "stimuli_trace        = res[\"stimuli_trace\"]\n",
    "onsets_by_id         = res[\"onsets_by_id\"]\n"
   ],
   "id": "25246cd084a39f2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons: 1984\n",
      "Number of time points: 3340\n",
      "2p duration (s): 1670.0\n",
      "60Hz duration from data (s): 1665.6333333333334\n",
      "Output stim trace shape: (3340,)\n",
      "Stimuli IDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Stimuli names: ['FL1', 'FL2', 'FL3', 'FLB', 'FR1', 'FR2', 'FR3', 'FRB', 'LLB', 'RLB']\n",
      "stim 1: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 2: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 3: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 4: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 5: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 6: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 7: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 8: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 9: 4 onsets | kept 4 trials | dropped 0\n",
      "stim 10: 4 onsets | kept 4 trials | dropped 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:09:34.138249Z",
     "start_time": "2025-11-20T17:09:33.992986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def intervals_from_labels(labels, fps, name_by_id=None):\n",
    "    \"\"\"\n",
    "    labels: 1D int array (T,), 0=no stim; >0 = stim id\n",
    "    fps: sampling rate of labels (e.g., fps_2p = 2.0)\n",
    "    name_by_id: optional dict {id:int -> name:str}\n",
    "    \"\"\"\n",
    "    labels = np.asarray(labels, dtype=int)\n",
    "    T = labels.size\n",
    "\n",
    "    # detect boundaries\n",
    "    prev = np.concatenate(([0], labels[:-1]))\n",
    "    change_idx = np.where(labels != prev)[0]\n",
    "\n",
    "    rows = []\n",
    "    open_id = 0\n",
    "    open_start = None\n",
    "\n",
    "    for i in change_idx:\n",
    "        curr_id = labels[i]\n",
    "        # close previous segment if one was open\n",
    "        if open_id != 0 and open_start is not None:\n",
    "            onset_f = open_start\n",
    "            offset_f = i              # exclusive\n",
    "            rows.append({\n",
    "                \"stimulus_id\": open_id,\n",
    "                \"stimulus_name\": name_by_id.get(open_id, str(open_id)) if name_by_id else open_id,\n",
    "                \"onset_frame\": onset_f,\n",
    "                \"offset_frame\": offset_f,\n",
    "                \"onset_time_s\": onset_f / fps,\n",
    "                \"offset_time_s\": offset_f / fps,\n",
    "                \"duration_frames\": offset_f - onset_f,\n",
    "                \"duration_s\": (offset_f - onset_f) / fps,\n",
    "            })\n",
    "        # start new segment if non-zero\n",
    "        if curr_id != 0:\n",
    "            open_id = curr_id\n",
    "            open_start = i\n",
    "        else:\n",
    "            open_id = 0\n",
    "            open_start = None\n",
    "\n",
    "    # close a segment that runs to the end\n",
    "    if open_id != 0 and open_start is not None:\n",
    "        onset_f = open_start\n",
    "        offset_f = T\n",
    "        rows.append({\n",
    "            \"stimulus_id\": open_id,\n",
    "            \"stimulus_name\": name_by_id.get(open_id, str(open_id)) if name_by_id else open_id,\n",
    "            \"onset_frame\": onset_f,\n",
    "            \"offset_frame\": offset_f,\n",
    "            \"onset_time_s\": onset_f / fps,\n",
    "            \"offset_time_s\": offset_f / fps,\n",
    "            \"duration_frames\": offset_f - onset_f,\n",
    "            \"duration_s\": (offset_f - onset_f) / fps,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values([\"onset_frame\", \"stimulus_id\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# ---- use it ----\n",
    "# stimuli_trace is your 2 Hz vector built with idx60 mapping\n",
    "# fps_2p = 2.0\n",
    "# Optional: if you have stim_id_map like {\"RL3\":1, \"RB\":2, ...}\n",
    "# name_by_id = {v:k for k,v in stim_id_map.items()}\n",
    "name_by_id = None\n",
    "\n",
    "table = intervals_from_labels(stimuli_trace, fps=fps_2p, name_by_id=name_by_id)\n",
    "print(table.head())\n"
   ],
   "id": "a464071ca04c46fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stimulus_id  stimulus_name  onset_frame  offset_frame  onset_time_s  \\\n",
      "0            6              6           26            58          13.0   \n",
      "1            9              9          109           141          54.5   \n",
      "2            7              7          192           224          96.0   \n",
      "3            8              8          275           308         137.5   \n",
      "4            3              3          358           391         179.0   \n",
      "\n",
      "   offset_time_s  duration_frames  duration_s  \n",
      "0           29.0               32        16.0  \n",
      "1           70.5               32        16.0  \n",
      "2          112.0               32        16.0  \n",
      "3          154.0               33        16.5  \n",
      "4          195.5               33        16.5  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:45:26.047208Z",
     "start_time": "2025-11-21T14:45:25.576876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accepted_rejected_rasters(\n",
    "    dfof: np.ndarray,             # (n_neurons, n_frames)\n",
    "    t=None,                       # (n_frames,) OR None OR scalar dt\n",
    "    kept_mask: np.ndarray=None,   # (n_neurons,), boolean\n",
    "    vmax: float = None,\n",
    "    vmin: float = 0.0,\n",
    "    perc_for_vmax: float = 99.0,\n",
    "    sort_by_peak_time: bool = False,\n",
    "    share_color_scale: bool = True,\n",
    "):\n",
    "    assert dfof.ndim == 2, \"dfof must be (n_neurons, n_frames)\"\n",
    "    n_neurons, n_frames = dfof.shape\n",
    "\n",
    "    # --- Build time axis / extent ---\n",
    "    if t is None:\n",
    "        x0, x1 = 0.0, float(n_frames - 1)\n",
    "        x_label = \"Frame\"\n",
    "    elif np.isscalar(t):  # t is a sampling interval (dt in seconds)\n",
    "        dt = float(t)\n",
    "        x0, x1 = 0.0, dt * (n_frames - 1)\n",
    "        x_label = \"Time (s)\"\n",
    "    else:\n",
    "        t = np.asarray(t)\n",
    "        assert t.ndim == 1 and t.size == n_frames, \"t must be 1-D with length n_frames\"\n",
    "        x0, x1 = float(t[0]), float(t[-1])\n",
    "        x_label = \"Time\"\n",
    "\n",
    "    if kept_mask is None:\n",
    "        kept_mask = np.ones(n_neurons, dtype=bool)\n",
    "    else:\n",
    "        kept_mask = np.asarray(kept_mask, dtype=bool)\n",
    "        assert kept_mask.shape[0] == n_neurons, \"kept_mask length must match n_neurons\"\n",
    "\n",
    "    kept_idx = np.flatnonzero(kept_mask)\n",
    "    rej_idx  = np.setdiff1d(np.arange(n_neurons), kept_idx)\n",
    "\n",
    "    # --- Color scaling ---\n",
    "    if vmax is None:\n",
    "        finite_vals = dfof[np.isfinite(dfof)]\n",
    "        vmax = np.percentile(finite_vals, perc_for_vmax) if finite_vals.size else 1.0\n",
    "        if not np.isfinite(vmax) or vmax <= 0:\n",
    "            vmax = np.nanmax(dfof) if np.isfinite(np.nanmax(dfof)) else 1.0\n",
    "\n",
    "    vmax_kept = vmax\n",
    "    vmax_rej  = vmax\n",
    "    if not share_color_scale:\n",
    "        if kept_idx.size:\n",
    "            tmp = np.percentile(dfof[kept_idx], perc_for_vmax)\n",
    "            vmax_kept = tmp if np.isfinite(tmp) and tmp > 0 else vmax\n",
    "        if rej_idx.size:\n",
    "            tmp = np.percentile(dfof[rej_idx], perc_for_vmax)\n",
    "            vmax_rej  = tmp if np.isfinite(tmp) and tmp > 0 else vmax\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "\n",
    "    def mat_for(idx):\n",
    "        M = dfof[idx] if idx.size else np.zeros((1, n_frames))\n",
    "        if sort_by_peak_time and idx.size > 1:\n",
    "            order = np.argsort(np.argmax(M, axis=1))\n",
    "            M = M[order]\n",
    "        return M\n",
    "\n",
    "    for (title, idx, vmax_here, ax) in [\n",
    "        (\"Accepted\", kept_idx, vmax_kept, axes[0]),\n",
    "        (\"Rejected\", rej_idx,  vmax_rej,  axes[1]),\n",
    "    ]:\n",
    "        M = mat_for(idx)\n",
    "        im = ax.imshow(\n",
    "            M,\n",
    "            aspect='auto',\n",
    "            interpolation='nearest',\n",
    "            origin='lower',\n",
    "            extent=[x0, x1, 0, M.shape[0]],\n",
    "            vmin=vmin,\n",
    "            vmax=vmax_here,\n",
    "            cmap='gray_r',       # high = dark\n",
    "        )\n",
    "        ax.set_title(f\"{title} (n={idx.size})\")\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(\"Neuron #\")\n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label(\"Î”F/F\")\n",
    "\n",
    "    if share_color_scale:\n",
    "        fig.suptitle(f\"Î”F/F rasters (shared vmin={vmin:.3g}, vmax={vmax:.3g})\", y=1.02)\n",
    "    else:\n",
    "        fig.suptitle(\n",
    "            f\"Î”F/F rasters (vmin={vmin:.3g}, kept vmax={vmax_kept:.3g}, rejected vmax={vmax_rej:.3g})\",\n",
    "            y=1.02\n",
    "        )\n",
    "    return fig, axes\n"
   ],
   "id": "1dc33a40c0a1c16e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:40:42.474922Z",
     "start_time": "2025-11-21T14:40:42.359492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def filter_neurons_by_trial_reliability(\n",
    "    dfof: np.ndarray,                    # (T, n_neurons)\n",
    "    trial_aligned_traces: dict,         # stim_id -> (n_neurons, win_length, n_trials)\n",
    "    stimuli_ids: list,\n",
    "    fps_2p: float,\n",
    "    plots_path: Path,\n",
    "    prefix: str = \"\",\n",
    "    folder_name: str | None = None,\n",
    "    make_plots: bool = True,\n",
    "    save_indices: bool = True,\n",
    "    hist_bins: int = 70,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute trial-to-trial reliability for each neuron, select neurons with\n",
    "    high reliability using an Otsu threshold, optionally plot, and save\n",
    "    kept neuron indices to disk.\n",
    "\n",
    "    Assumes:\n",
    "      - dfof is (T, n_neurons)\n",
    "      - trial_aligned_traces[stim] is (n_neurons, win_length, n_trials)\n",
    "    \"\"\"\n",
    "\n",
    "    T, n_neurons = dfof.shape\n",
    "\n",
    "    # --- reliability per neuron x stimulus ---\n",
    "    reliability_per_stim = np.full((n_neurons, len(stimuli_ids)), np.nan, dtype=float)\n",
    "\n",
    "    for j, stim in enumerate(stimuli_ids):\n",
    "        aligned_neural_traces = trial_aligned_traces[stim]  # (n_neurons, win_length, n_trials)\n",
    "        _, _, n_trials = aligned_neural_traces.shape\n",
    "\n",
    "        if n_trials < 2:\n",
    "            # can't compute correlations with 1 trial â†’ leave as NaN\n",
    "            continue\n",
    "\n",
    "        for i in range(n_neurons):\n",
    "            neuron_trace = aligned_neural_traces[i, :, :]  # (time, trials)\n",
    "\n",
    "            # Compute trial-to-trial correlation matrix (trials x trials)\n",
    "            corr_mat = np.corrcoef(neuron_trace.T)\n",
    "\n",
    "            # Ignore self-correlations by setting diagonal to NaN\n",
    "            np.fill_diagonal(corr_mat, np.nan)\n",
    "\n",
    "            # Mean correlation (reliability) across all trial pairs\n",
    "            reliability_per_stim[i, j] = np.nanmean(corr_mat)\n",
    "\n",
    "    # --- max reliability across stimuli & Otsu threshold ---\n",
    "    max_stimuli_correlation = np.nanmax(reliability_per_stim, axis=1)\n",
    "    nanfiltered_max = max_stimuli_correlation[np.isfinite(max_stimuli_correlation)]\n",
    "\n",
    "    if nanfiltered_max.size > 0:\n",
    "        otsu_threshold = float(threshold_otsu(nanfiltered_max))\n",
    "    else:\n",
    "        otsu_threshold = np.nan\n",
    "\n",
    "    kept_mask = np.isfinite(max_stimuli_correlation) & (max_stimuli_correlation >= otsu_threshold)\n",
    "    kept_neuron_indices = np.flatnonzero(kept_mask)\n",
    "    kept_pct = (100.0 * kept_neuron_indices.size / n_neurons) if n_neurons else 0.0\n",
    "\n",
    "    # --- save indices (but not figures) ---\n",
    "    if save_indices:\n",
    "        if plots_path is None:\n",
    "            raise ValueError(\"plots_path must be provided if save_indices=True\")\n",
    "\n",
    "        # Decide where to save\n",
    "        out_dir = plots_path / folder_name if folder_name is not None else plots_path\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save kept indices\n",
    "        out_idx = out_dir / f\"{prefix}_kept_neuron_indices.npy\"\n",
    "        np.save(out_idx, kept_neuron_indices)\n",
    "        print(f\"Saved kept neuron indices to: {out_idx}\")\n",
    "\n",
    "    # --- plots (purely for visualization, not saved) ---\n",
    "    if make_plots and nanfiltered_max.size > 0:\n",
    "        # 1) Histogram of reliability + threshold\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.hist(nanfiltered_max, bins=hist_bins)\n",
    "        ax.axvline(otsu_threshold, linestyle=\"--\", color=\"k\")\n",
    "        ax.set(\n",
    "            title=(\n",
    "                \"Reliability of response across stimuli\\n\"\n",
    "                f\"Otsu {otsu_threshold:.2f} â€” kept {kept_pct:.1f}% \"\n",
    "                f\"({kept_neuron_indices.size} ROIs)\"\n",
    "            ),\n",
    "            xlabel=\"max avg intertrial correlation\",\n",
    "            ylabel=\"neuron count\",\n",
    "        )\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 2) Curve: #ROIs kept vs threshold\n",
    "        low = max(0.0, float(np.nanmin(nanfiltered_max)))\n",
    "        high = min(1.0, max(float(np.nanmax(nanfiltered_max)), low + 1e-6))\n",
    "        thr_grid = np.linspace(low, high, 51)\n",
    "        counts = [np.sum(nanfiltered_max >= thr) for thr in thr_grid]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(thr_grid, counts, marker=\"o\", linewidth=1)\n",
    "        ax.set(\n",
    "            title=\"ROIs kept vs threshold\",\n",
    "            xlabel=\"Threshold\",\n",
    "            ylabel=\"# ROIs kept\",\n",
    "        )\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 3) Rasters accepted vs rejected, with X-axis in seconds\n",
    "        # dfof is (T, n_neurons) â†’ transpose for raster function\n",
    "        dt = 1.0 / float(fps_2p)\n",
    "        _fig_r, _axes_r = plot_accepted_rejected_rasters(\n",
    "            dfof=dfof.T,\n",
    "            t=dt,  # scalar dt â†’ seconds on X\n",
    "            kept_mask=kept_mask,\n",
    "            sort_by_peak_time=True,\n",
    "            share_color_scale=True,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"reliability_per_stim\": reliability_per_stim,\n",
    "        \"max_stimuli_correlation\": max_stimuli_correlation,\n",
    "        \"nanfiltered_max\": nanfiltered_max,\n",
    "        \"otsu_threshold\": otsu_threshold,\n",
    "        \"kept_mask\": kept_mask,\n",
    "        \"kept_neuron_indices\": kept_neuron_indices,\n",
    "    }\n"
   ],
   "id": "13b3f48880f3199e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:05:04.645037Z",
     "start_time": "2025-11-21T15:05:04.512349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = filter_neurons_by_trial_reliability(\n",
    "    dfof=dfof,                        # shape (T, n_neurons)\n",
    "    trial_aligned_traces=trial_aligned_traces,\n",
    "    stimuli_ids=stimuli_ids,\n",
    "    fps_2p=fps_2p,\n",
    "    plots_path=paths[\"plots_path\"],\n",
    "    prefix=paths[\"prefix\"],\n",
    "    folder_name=\"reliability_filter\",\n",
    "    make_plots=True,      # switch to False if you don't want any plots\n",
    "    save_indices=True,    # switch to False if you don't want to save the .npy\n",
    ")\n",
    "\n",
    "kept_neuron_indices = results[\"kept_neuron_indices\"]\n"
   ],
   "id": "a3dcfbcc10409d32",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_neurons_by_trial_reliability' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m results = filter_neurons_by_trial_reliability(\n\u001B[32m      2\u001B[39m     dfof=dfof,                        \u001B[38;5;66;03m# shape (T, n_neurons)\u001B[39;00m\n\u001B[32m      3\u001B[39m     trial_aligned_traces=trial_aligned_traces,\n\u001B[32m      4\u001B[39m     stimuli_ids=stimuli_ids,\n\u001B[32m      5\u001B[39m     fps_2p=fps_2p,\n\u001B[32m      6\u001B[39m     plots_path=paths[\u001B[33m\"\u001B[39m\u001B[33mplots_path\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m      7\u001B[39m     prefix=paths[\u001B[33m\"\u001B[39m\u001B[33mprefix\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m      8\u001B[39m     folder_name=\u001B[33m\"\u001B[39m\u001B[33mreliability_filter\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m     make_plots=\u001B[38;5;28;01mTrue\u001B[39;00m,      \u001B[38;5;66;03m# switch to False if you don't want any plots\u001B[39;00m\n\u001B[32m     10\u001B[39m     save_indices=\u001B[38;5;28;01mTrue\u001B[39;00m,    \u001B[38;5;66;03m# switch to False if you don't want to save the .npy\u001B[39;00m\n\u001B[32m     11\u001B[39m )\n\u001B[32m     13\u001B[39m kept_neuron_indices = results[\u001B[33m\"\u001B[39m\u001B[33mkept_neuron_indices\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'filter_neurons_by_trial_reliability' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:47:47.322777Z",
     "start_time": "2025-11-21T14:47:46.865184Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f09592fe44759a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept neuron indices: (641,)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:05:09.616312Z",
     "start_time": "2025-11-21T15:05:08.559277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter neurons base on correlation with the stimuli\n",
    "# create array to store reliability metric\n",
    "T, n_neurons= dfof.shape\n",
    "\n",
    "reliability_per_stim = np.full((n_neurons, len(stimuli_ids)), np.nan, dtype=float)\n",
    "\n",
    "for j, stim in enumerate(stimuli_ids):\n",
    "    aligned_neural_traces = trial_aligned_traces[stim]  #(n_neurons, win_lenght, n_trials)\n",
    "\n",
    "    for i in range(n_neurons):\n",
    "        neuron_trace = aligned_neural_traces[i, :, :]  # neuron trace 2D array (time, trials)\n",
    "\n",
    "        # Compute trial-to-trial correlation matrix (shape: trials x trials)\n",
    "        correlation_matrix = np.corrcoef(neuron_trace.T)\n",
    "\n",
    "        # Ignore self-correlations by setting diagonal to NaN\n",
    "        np.fill_diagonal(correlation_matrix, np.nan)\n",
    "\n",
    "        # Compute mean correlation (reliability) across all trial pairs\n",
    "        reliability_per_stim[i, j] = np.nanmean(correlation_matrix)  #\n",
    "\n",
    "# Compute max reliability value across all stimuli and filter out nan values\n",
    "max_stimuli_correlation = np.nanmax(reliability_per_stim, axis=1)\n",
    "nanfiltered_max_stimuli_correlation = max_stimuli_correlation[\n",
    "    np.isfinite(max_stimuli_correlation)]  # select only finite (not nan values)\n",
    "otsu_threshold = threshold_otsu(nanfiltered_max_stimuli_correlation)\n",
    "\n",
    "#Build keep mask in the original neuron space (not nanfiltered) and get indices\n",
    "kept_mask = np.isfinite(max_stimuli_correlation) & (max_stimuli_correlation >= otsu_threshold)\n",
    "kept_neuron_indices = np.flatnonzero(kept_mask)  #return indices where the values are true\n"
   ],
   "id": "b8cadc0571c66b46",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:17:05.043971Z",
     "start_time": "2025-11-21T14:17:04.708899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot a histograme of the correlation between neuron activity and stimuli\n",
    "hist_bins = 70\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.hist(nanfiltered_max_stimuli_correlation, bins=hist_bins)\n",
    "kept_pct = (100.0 * kept_neuron_indices.size / n_neurons) if n_neurons else 0.0\n",
    "ax.axvline(otsu_threshold, linestyle=\"--\", color=\"k\")\n",
    "ax.set(title=f\"Reliability of response across stimuli \\n Otsu {otsu_threshold:.2f} â€” kept {kept_pct:.1f}% ({kept_neuron_indices.size} ROIs)\",\n",
    "       xlabel=\"max avg intertrial correlation\", ylabel=\"neuron count\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "22a1d3c02d4ccca3",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:17:10.437584Z",
     "start_time": "2025-11-21T14:17:10.275996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the number of neurons accepted as a function of threshold.(again correlation)\n",
    "\n",
    "low = max(0.0, float(np.nanmin(nanfiltered_max_stimuli_correlation)))\n",
    "high = min(1.0, max(float(np.nanmax(nanfiltered_max_stimuli_correlation)), low + 1e-6))\n",
    "thr_grid = np.linspace(low, high, 51)\n",
    "\n",
    "counts = [np.sum(nanfiltered_max_stimuli_correlation >= thr) for thr in thr_grid]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(thr_grid, counts, marker=\"o\", linewidth=1)\n",
    "ax.set(title=\"ROIs kept vs threshold\",\n",
    "       xlabel=\"Threshold\", ylabel=\"# ROIs kept\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "db09375a41b3f54d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:05:14.614493Z",
     "start_time": "2025-11-21T15:05:14.491798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot neurons that where accepted and compared with neurons that does not pass the filter\n",
    "\n",
    "def plot_accepted_rejected_rasters(\n",
    "    dfof: np.ndarray,             # (n_neurons, n_frames)\n",
    "    t=None,                       # (n_frames,) OR None OR scalar dt\n",
    "    kept_mask: np.ndarray=None,   # (n_neurons,), boolean\n",
    "    vmax: float = None,\n",
    "    vmin: float = 0.0,\n",
    "    perc_for_vmax: float = 99.0,\n",
    "    sort_by_peak_time: bool = False,\n",
    "    share_color_scale: bool = True,\n",
    "):\n",
    "    assert dfof.ndim == 2, \"dfof must be (n_neurons, n_frames)\"\n",
    "    n_neurons, n_frames = dfof.shape\n",
    "\n",
    "    # --- Build time axis or extent ---\n",
    "    if t is None:\n",
    "        # no time given â†’ use frame indices\n",
    "        x0, x1 = 0.0, float(n_frames - 1)\n",
    "        x_label = \"Frame\"\n",
    "    elif np.isscalar(t):  # treat as dt (sampling interval)\n",
    "        dt = float(t)\n",
    "        x0, x1 = 0.0, dt * (n_frames - 1)\n",
    "        x_label = \"Time (s)\"\n",
    "    else:\n",
    "        t = np.asarray(t)\n",
    "        assert t.ndim == 1 and t.size == n_frames, \"t must be 1-D with length n_frames\"\n",
    "        x0, x1 = float(t[0]), float(t[-1])\n",
    "        x_label = \"Time\"\n",
    "\n",
    "    if kept_mask is None:\n",
    "        kept_mask = np.ones(n_neurons, dtype=bool)\n",
    "    else:\n",
    "        kept_mask = np.asarray(kept_mask, dtype=bool)\n",
    "        assert kept_mask.shape[0] == n_neurons, \"kept_mask length must match n_neurons\"\n",
    "\n",
    "    kept_idx = np.flatnonzero(kept_mask)\n",
    "    rej_idx  = np.setdiff1d(np.arange(n_neurons), kept_idx)\n",
    "\n",
    "    # --- Color scaling ---\n",
    "    if vmax is None:\n",
    "        finite_vals = dfof[np.isfinite(dfof)]\n",
    "        vmax = np.percentile(finite_vals, perc_for_vmax) if finite_vals.size else 1.0\n",
    "        if not np.isfinite(vmax) or vmax <= 0:\n",
    "            vmax = np.nanmax(dfof) if np.isfinite(np.nanmax(dfof)) else 1.0\n",
    "\n",
    "    vmax_kept = vmax\n",
    "    vmax_rej  = vmax\n",
    "    if not share_color_scale:\n",
    "        if kept_idx.size:\n",
    "            tmp = np.percentile(dfof[kept_idx], perc_for_vmax)\n",
    "            vmax_kept = tmp if np.isfinite(tmp) and tmp > 0 else vmax\n",
    "        if rej_idx.size:\n",
    "            tmp = np.percentile(dfof[rej_idx], perc_for_vmax)\n",
    "            vmax_rej  = tmp if np.isfinite(tmp) and tmp > 0 else vmax\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "\n",
    "    def mat_for(idx):\n",
    "        M = dfof[idx] if idx.size else np.zeros((1, n_frames))\n",
    "        if sort_by_peak_time and idx.size > 1:\n",
    "            order = np.argsort(np.argmax(M, axis=1))\n",
    "            M = M[order]\n",
    "        return M\n",
    "\n",
    "    for (title, idx, vmax_here, ax) in [\n",
    "        (\"Accepted\", kept_idx, vmax_kept, axes[0]),\n",
    "        (\"Rejected\", rej_idx,  vmax_rej,  axes[1]),\n",
    "    ]:\n",
    "        M = mat_for(idx)\n",
    "        im = ax.imshow(\n",
    "            M,\n",
    "            aspect='auto',\n",
    "            interpolation='nearest',\n",
    "            origin='lower',\n",
    "            extent=[x0, x1, 0, M.shape[0]],\n",
    "            vmin=vmin,\n",
    "            vmax=vmax_here,\n",
    "            cmap='gray_r',       # high = dark\n",
    "        )\n",
    "        ax.set_title(f\"{title} (n={idx.size})\")\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(\"Neuron #\")\n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label(\"Î”F/F\")\n",
    "\n",
    "    if share_color_scale:\n",
    "        fig.suptitle(f\"Î”F/F rasters (shared vmin={vmin:.3g}, vmax={vmax:.3g})\", y=1.02)\n",
    "    else:\n",
    "        fig.suptitle(\n",
    "            f\"Î”F/F rasters (vmin={vmin:.3g}, kept vmax={vmax_kept:.3g}, rejected vmax={vmax_rej:.3g})\",\n",
    "            y=1.02\n",
    "        )\n",
    "    return fig, axes\n"
   ],
   "id": "b25b71242bf36f83",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:05:18.631824Z",
     "start_time": "2025-11-21T15:05:18.177941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you already have:\n",
    "# dfof: (n_neurons, n_frames) Î”F/F\n",
    "# time_2p: (n_frames,) time vector\n",
    "# kept_mask: boolean (n_neurons,) from your Otsu thresholding\n",
    "traces=dfof.T  # shape (n_neurons, T)\n",
    "plot_accepted_rejected_rasters(traces, kept_mask=kept_mask)\n",
    "\n"
   ],
   "id": "3915a8656300b4d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 2400x1200 with 4 Axes>,\n",
       " array([<Axes: title={'center': 'Accepted (n=641)'}, xlabel='Frame', ylabel='Neuron #'>,\n",
       "        <Axes: title={'center': 'Rejected (n=1343)'}, xlabel='Frame', ylabel='Neuron #'>],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:06:25.757250Z",
     "start_time": "2025-11-21T15:06:25.619356Z"
    }
   },
   "cell_type": "code",
   "source": "print(kept_mask)",
   "id": "a28b2bb58b547ae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False ... False False False]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:28:50.521865Z",
     "start_time": "2025-11-18T16:28:50.268252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# average the  activity of neurons in repetition per stimuli\n",
    "\n",
    "dt = 1.0 / float(fps_2p) #time per frame (the sampling interval) in seconds\n",
    "\n",
    "# Containers (per stimulus â†’ arrays of shape (n_kept,))\n",
    "mean_traces = {}   # trial-averaged timecourses (kept neurons)\n",
    "peaks = {}\n",
    "aucs  = {}\n",
    "averages = {}\n",
    "\n",
    "for stim in stimuli_ids:\n",
    "    X = trial_aligned_traces[stim]                      # (n_neurons, win_lenght, n_trials)\n",
    "    Xkept = X[kept_neuron_indices, :, :]                   # filter kept neurons\n",
    "    mean_trace = np.nanmean(Xkept, axis=2)                # (kept_neurons, win_lenght)\n",
    "    mean_traces[stim] = mean_trace\n",
    "\n",
    "    # Stimulus window (without pre stim frames)\n",
    "    Y = mean_trace[:, pre_frames:win_lenght]                # (n_kept, n_post)\n",
    "    peaks[stim] = np.nanmax(Y, axis=1) # peak Î”F/F\n",
    "    aucs[stim]  = np.trapezoid(np.nan_to_num(Y), dx=dt, axis=1)  # AUC (Î”F/F * s), NaNsâ†’0\n",
    "    averages[stim] = np.nanmean(Y, axis=1)"
   ],
   "id": "10c4a56a30fe60bf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:28:54.316288Z",
     "start_time": "2025-11-18T16:28:54.205080Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #select colors and linestyles for stimuli\n",
    "# --- Set A (default) ----------------------------------------------------------\n",
    "colors_A = {\n",
    "    'LLB': sns.color_palette('Blues', 8)[7],\n",
    "    'RLB': sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'FLB': sns.color_palette('Blues', 8)[7],\n",
    "    'FRB': sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'FL1': sns.color_palette('PuRd', as_cmap=True)(0.9),\n",
    "    'FL2': sns.color_palette('PuRd', as_cmap=True)(0.6),\n",
    "    'FL3': sns.color_palette('dark:#404040', 10)[7],\n",
    "    'FR1': sns.color_palette('PuRd', as_cmap=True)(0.9),\n",
    "    'FR2': sns.color_palette('PuRd', as_cmap=True)(0.6),\n",
    "    'FR3': sns.color_palette('dark:#404040', 10)[7],\n",
    "}\n",
    "linestyles_A = {\n",
    "    'FLB': '--',\n",
    "    'FRB': '--',\n",
    "    'FL1': '--',\n",
    "    'FL2': '--',\n",
    "    'FL3': '--',\n",
    "}\n",
    "\n",
    "# --- Set B (rocking experiment) ----------------------------------------------\n",
    "colors_B = {\n",
    "    'LB':   sns.color_palette('Blues', 8)[7],\n",
    "    'RR1':  sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'RB':   sns.color_palette('Blues', 8)[7],\n",
    "    'RL1':  sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'RR2':  sns.color_palette('PuRd', as_cmap=True)(0.9),\n",
    "    'RR3':  sns.color_palette('PuRd', as_cmap=True)(0.6),\n",
    "    'RLR1': sns.color_palette('dark:#404040', 10)[7],\n",
    "    'RL2':  sns.color_palette('PuRd', as_cmap=True)(0.9),   # fixed case from 'Rl2' â†’ 'RL2'\n",
    "    'RL3':  sns.color_palette('PuRd', as_cmap=True)(0.6),\n",
    "    'RLR2': sns.color_palette('dark:#404040', 10)[7],\n",
    "}\n",
    "linestyles_B = {\n",
    "    'LB': '--',\n",
    "    'RL1': '--',\n",
    "    'RL2': '--',\n",
    "    'RL3': '--',\n",
    "    'RLR2': '--',\n",
    "}\n",
    "\n",
    "# --- Select set based on experiment name --------------------------------------\n",
    "if experiment_name == 'Exp_2_rocking_1':\n",
    "    stimuli_colors = colors_B\n",
    "    stimuli_linestyles = linestyles_B\n",
    "else:\n",
    "    stimuli_colors = colors_A\n",
    "    stimuli_linestyles = linestyles_A\n",
    "\n",
    "print(\"Using colors for:\", experiment_name)\n",
    "print(stimuli_linestyles)"
   ],
   "id": "7aa8bdd26f7de435",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using colors for: Exp_1_flickering\n",
      "{'FLB': '--', 'FRB': '--', 'FL1': '--', 'FL2': '--', 'FL3': '--'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:29:17.903281Z",
     "start_time": "2025-11-18T16:29:17.788226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this function plot Df/F as a function of time per stimuli...\n",
    "\n",
    "def plot_stimulus_means(\n",
    "    mean_traces,\n",
    "    stimuli_ids,\n",
    "    stimuli_names,                 # list of display names (used to look up styles)\n",
    "    kept_neuron_indices,\n",
    "    fps_2p,\n",
    "    win_lenght,\n",
    "    pre_frames,\n",
    "    guide_times=(0.0, 8.0, 18.4),\n",
    "    title_prefix=\"neurons resposive to stimuli\",\n",
    "    show_sem=True,\n",
    "    # NEW: pass styles in\n",
    "    stimuli_colors: dict | None = None,     # e.g., {\"LLB\": (r,g,b), \"FLB\": ...}\n",
    "    stimuli_linestyles: dict | None = None, # e.g., {\"FLB\": \"--\", \"FRB\": \"--\"}\n",
    "    # saving controls\n",
    "    save: bool = False,\n",
    "    plots_path: Path | str | None = None,\n",
    "    prefix: str | None = None,\n",
    "    dpi: int = 600,\n",
    "    close_after: bool = False,\n",
    "    comment=\"all_stimuli\" # for saving\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots mean Â± SEM per stimulus.\n",
    "    Styles are looked up by stimulus *name* in `stimuli_colors` and `stimuli_linestyles`.\n",
    "    \"\"\"\n",
    "    # defaults if not provided\n",
    "    if stimuli_colors is None:     stimuli_colors = {}\n",
    "    if stimuli_linestyles is None: stimuli_linestyles = {}\n",
    "\n",
    "    # time axis (s), 0 at static onset\n",
    "    t = (np.arange(win_lenght) - pre_frames) / float(fps_2p)\n",
    "    n_sel = int(kept_neuron_indices.size)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4.5))\n",
    "    color_by_stim = {}\n",
    "\n",
    "    # optional warnings for missing styles\n",
    "    missing_colors = [nm for nm in stimuli_names if nm not in stimuli_colors]\n",
    "    missing_ls     = [nm for nm in stimuli_names if nm not in stimuli_linestyles]\n",
    "    if missing_colors:\n",
    "        print(\"[warn] No color for:\", missing_colors, \"â†’ using Matplotlib defaults.\")\n",
    "    if missing_ls:\n",
    "        print(\"[warn] No linestyle for:\", missing_ls, \"â†’ using solid '-'.\")\n",
    "\n",
    "    for i, stim in enumerate(stimuli_ids):\n",
    "        name = stimuli_names[i]                 # look up styles by NAME\n",
    "        M = mean_traces[stim]                   # (n_kept, win_lenght)\n",
    "        trace_mean = np.nanmean(M, axis=0)\n",
    "        trace_sd   = np.nanstd(M,  axis=0)\n",
    "        trace_sem  = trace_sd / np.sqrt(max(n_sel, 1))\n",
    "\n",
    "        color = stimuli_colors.get(name, None)        # None â†’ mpl default\n",
    "        ls    = stimuli_linestyles.get(name, \"-\")     # default solid\n",
    "\n",
    "        (line,) = ax.plot(t, trace_mean, label=name, color=color, linestyle=ls)\n",
    "        color_by_stim[name] = line.get_color()\n",
    "\n",
    "        if show_sem:\n",
    "            ax.fill_between(\n",
    "                t, trace_mean - trace_sem, trace_mean + trace_sem,\n",
    "                alpha=0.18, color=line.get_color(), linewidth=0\n",
    "            )\n",
    "\n",
    "    # visual guides\n",
    "    static_onset, motion_onset, motion_offset = guide_times\n",
    "    ax.axvline(static_onset, linestyle=\"--\", linewidth=1, color=\"grey\", label=\"static onset\")\n",
    "    ax.text(static_onset - 0.5, 0.85, \"static\", rotation=90, va=\"bottom\", ha=\"center\",\n",
    "            transform=ax.get_xaxis_transform())\n",
    "    ax.axvline(motion_onset, linewidth=1, color=\"k\", label=\"motion onset\")\n",
    "    ax.text(motion_onset + 1.5, 0.85, \"motion\", rotation=90, va=\"bottom\", ha=\"center\",\n",
    "            transform=ax.get_xaxis_transform())\n",
    "    ax.axvline(motion_offset, linestyle=\"--\", linewidth=1, color=\"grey\")\n",
    "\n",
    "    # cosmetics\n",
    "    ax.set(title=f\"{title_prefix}\\n(n={n_sel})\",\n",
    "           xlabel=\"Time (s) relative to onset\",\n",
    "           ylabel=\"Î”F/F\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.legend(frameon=False, loc=\"center left\", bbox_to_anchor=(1.02, 0.5), borderaxespad=0.0)\n",
    "    plt.subplots_adjust(right=0.78)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_png = None\n",
    "    if save:\n",
    "        if plots_path is None or prefix is None:\n",
    "            print(\"âš ï¸  Save was requested but `plots_path` or `prefix` is missingâ€”skipping save.\")\n",
    "        else:\n",
    "            plots_path = Path(plots_path)\n",
    "            plots_path.mkdir(parents=True, exist_ok=True)\n",
    "            out_png = plots_path / f\"{prefix}_dfof_as_func_of_time_{comment}.png\"\n",
    "            fig.savefig(out_png, dpi=dpi, bbox_inches=\"tight\")\n",
    "            print(\"âœ… Saved:\", out_png)\n",
    "\n",
    "    if close_after:\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    return fig, ax, color_by_stim, out_png\n"
   ],
   "id": "b802d0e1013fa1f6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:32:29.178493Z",
     "start_time": "2025-11-18T16:32:27.889404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax, used_colors, out_path = plot_stimulus_means(\n",
    "    mean_traces=mean_traces,\n",
    "    stimuli_ids=stimuli_ids,\n",
    "    stimuli_names=stimuli_names,\n",
    "    kept_neuron_indices=kept_neuron_indices,\n",
    "    fps_2p=fps_2p,\n",
    "    win_lenght=win_lenght,\n",
    "    pre_frames=pre_frames,\n",
    "    guide_times=(0.0, 8.0, 18.4),\n",
    "    plots_path=paths[\"plots_path\"],       # Path object or str\n",
    "    prefix=paths['prefix'],               # e.g., \"exp12_mouseA\"\n",
    "    dpi=600,\n",
    "    save=True,\n",
    "    stimuli_colors=stimuli_colors,            # <â€” pass styles here\n",
    "    stimuli_linestyles=stimuli_linestyles,\n",
    "    close_after=False,\n",
    "    comment=\"all_stimuli\" # for saving\n",
    ")\n"
   ],
   "id": "e8b1fc01821c6710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] No linestyle for: ['FR1', 'FR2', 'FR3', 'LLB', 'RLB'] â†’ using solid '-'.\n",
      "âœ… Saved: C:\\Users\\suribear\\OneDrive - UniversitÃ© de Lausanne\\Lab\\Data\\2p\\L433_f02_Exp_1_flickering\\03_analysis\\functional\\plots\\stimuli_selected_dFoF\\L433_f02_dfof_as_func_of_time_all_stimuli.png\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:35:27.695662Z",
     "start_time": "2025-11-18T16:35:27.416599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map ID -> name (from your parallel lists)\n",
    "id2name = {sid: stimuli_names[i] for i, sid in enumerate(stimuli_ids)}\n",
    "\n",
    "# Define merged groups by ID\n",
    "# keep the FIRST ID of each group as the new key\n",
    "groups = {\n",
    "    1: [1, 2],\n",
    "    2: [3, 8],\n",
    "    3: [4,9],\n",
    "    4: [5,10],\n",
    "    5: [6],\n",
    "    6: [7]\n",
    "}\n",
    "\n",
    "dt = 1.0 / float(fps_2p)\n",
    "\n",
    "mean_traces = {}\n",
    "peaks = {}\n",
    "aucs  = {}\n",
    "averages = {}\n",
    "\n",
    "for new_id, member_ids in groups.items():\n",
    "    # X = concat trials from all member stimuli along axis=2\n",
    "    X = np.concatenate([trial_aligned_traces[sid] for sid in member_ids], axis=2)\n",
    "    print(X.shape)\n",
    "    Xkept = X[kept_neuron_indices, :, :]\n",
    "    mean_trace = np.nanmean(Xkept, axis=2)              # (n_kept, win_lenght)\n",
    "    mean_traces[new_id] = mean_trace\n",
    "\n",
    "    Y = mean_trace[:, pre_frames:win_lenght]\n",
    "    peaks[new_id]    = np.nanmax(Y, axis=1)\n",
    "    aucs[new_id]     = np.trapezoid(np.nan_to_num(Y), dx=dt, axis=1)\n",
    "    averages[new_id] = np.nanmean(Y, axis=1)\n",
    "\n",
    "# Update the lists you use for plotting (IDs stay IDs; names by id2name)\n",
    "stimuli_ids   = list(groups.keys())                     # [1, 3, 6, 7, 8]\n",
    "stimuli_names = ['Bouts', 'R_1', 'R_2', 'R_3', 'RBS_1', 'RBS_2']\n",
    "\n",
    "# stimuli_colors\n",
    "colors_C = {\n",
    "    'Bouts': sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'R_1':  sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'R_2':  sns.color_palette('Blues', 8)[7],\n",
    "    'R_3':   sns.color_palette('dark:#404040', 10)[7],\n",
    "    'RBS_1': sns.color_palette('PuRd', as_cmap=True)(0.9),\n",
    "    'RBS_2': sns.color_palette('PuRd', as_cmap=True)(0.6),\n",
    "}\n",
    "linestyles_C = {\n",
    "    'R_1': '--',\n",
    "    'RBS_2': '--',\n",
    "    }\n",
    "\n",
    "fig, ax, used_colors, out_path = plot_stimulus_means(\n",
    "    mean_traces=mean_traces,\n",
    "    stimuli_ids=stimuli_ids,\n",
    "    stimuli_names=stimuli_names,\n",
    "    kept_neuron_indices=kept_neuron_indices,\n",
    "    fps_2p=fps_2p,\n",
    "    win_lenght=win_lenght,\n",
    "    pre_frames=pre_frames,\n",
    "    guide_times=(0.0, 8.0, 18.4),\n",
    "    plots_path=paths['plots_path'],       # Path object or str\n",
    "    prefix=paths['prefix'],               # e.g., \"exp12_mouseA\"\n",
    "    dpi=600,\n",
    "    save=False,\n",
    "    stimuli_colors=colors_C,            # <â€” pass styles here\n",
    "    stimuli_linestyles=linestyles_C,\n",
    "    close_after=False,\n",
    "    comment=\"merge_stimuli\" # for saving\n",
    ")"
   ],
   "id": "68823388cf803f6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 4)\n",
      "(1984, 68, 4)\n",
      "[warn] No linestyle for: ['Bouts', 'R_2', 'R_3', 'RBS_1'] â†’ using solid '-'.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:40:48.194160Z",
     "start_time": "2025-11-18T16:40:47.984414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map ID -> name (from your parallel lists)\n",
    "id2name = {sid: stimuli_names[i] for i, sid in enumerate(stimuli_ids)}\n",
    "\n",
    "# Define merged groups by ID\n",
    "# keep the FIRST ID of each group as the new key\n",
    "groups = {\n",
    "    1: [4, 8],\n",
    "    2: [9, 10],\n",
    "    3: [1,5],\n",
    "    4: [2,6],\n",
    "    5: [3,7],\n",
    "}\n",
    "\n",
    "dt = 1.0 / float(fps_2p)\n",
    "\n",
    "mean_traces = {}\n",
    "peaks = {}\n",
    "aucs  = {}\n",
    "averages = {}\n",
    "\n",
    "for new_id, member_ids in groups.items():\n",
    "    # X = concat trials from all member stimuli along axis=2\n",
    "    X = np.concatenate([trial_aligned_traces[sid] for sid in member_ids], axis=2)\n",
    "    print(X.shape)\n",
    "    Xkept = X[kept_neuron_indices, :, :]\n",
    "    mean_trace = np.nanmean(Xkept, axis=2)              # (n_kept, win_lenght)\n",
    "    mean_traces[new_id] = mean_trace\n",
    "\n",
    "    Y = mean_trace[:, pre_frames:win_lenght]\n",
    "    peaks[new_id]    = np.nanmax(Y, axis=1)\n",
    "    aucs[new_id]     = np.trapezoid(np.nan_to_num(Y), dx=dt, axis=1)\n",
    "    averages[new_id] = np.nanmean(Y, axis=1)\n",
    "\n",
    "# Update the lists you use for plotting (IDs stay IDs; names by id2name)\n",
    "stimuli_ids   = list(groups.keys())                     # [1, 3, 6, 7, 8]\n",
    "stimuli_names = ['F_Bouts', 'Bouts', 'F_1', 'F_2', 'F_3']\n",
    "\n",
    "# stimuli_colors\n",
    "colors_C = {\n",
    "    'F_Bouts': sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'Bouts':  sns.color_palette('Greens', as_cmap=True)(0.6),\n",
    "    'F_1':  sns.color_palette('Blues', 8)[7],\n",
    "    'F_2':   sns.color_palette('dark:#404040', 10)[7],\n",
    "    'F_3': sns.color_palette('PuRd', as_cmap=True)(0.9),\n",
    "\n",
    "}\n",
    "linestyles_C = {\n",
    "    'F_Bouts': '--',\n",
    "    }\n",
    "\n",
    "fig, ax, used_colors, out_path = plot_stimulus_means(\n",
    "    mean_traces=mean_traces,\n",
    "    stimuli_ids=stimuli_ids,\n",
    "    stimuli_names=stimuli_names,\n",
    "    kept_neuron_indices=kept_neuron_indices,\n",
    "    fps_2p=fps_2p,\n",
    "    win_lenght=win_lenght,\n",
    "    pre_frames=pre_frames,\n",
    "    guide_times=(0.0, 8.0, 18.4),\n",
    "    plots_path=paths['plots_path'],       # Path object or str\n",
    "    prefix=paths['prefix'],               # e.g., \"exp12_mouseA\"\n",
    "    dpi=600,\n",
    "    save=False,\n",
    "    stimuli_colors=colors_C,            # <â€” pass styles here\n",
    "    stimuli_linestyles=linestyles_C,\n",
    "    close_after=False,\n",
    "    comment=\"merge_stimuli\"\n",
    ")"
   ],
   "id": "f6b74dc602a921da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "(1984, 68, 8)\n",
      "[warn] No linestyle for: ['Bouts', 'F_1', 'F_2', 'F_3'] â†’ using solid '-'.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:41:52.637098Z",
     "start_time": "2025-11-18T16:41:52.442594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# assume fps_stim is defined (e.g., 60) and ax is your matplotlib axes\n",
    "fps_stim=60\n",
    "deltaF_F=dfof[:,kept_mask]\n",
    "exp_log= adjusted_log\n",
    "for stim_name, timing in stimuli_durations.items():\n",
    "    start_f = timing.get('start_frame', timing.get('motion_start_frame'))\n",
    "    end_f   = timing.get('end_frame',   timing.get('motion_end_frame'))\n",
    "    if start_f is None or end_f is None:\n",
    "        print(f\"Skipping {stim_name}: no start/end frame keys\")\n",
    "        continue\n",
    "\n",
    "    start = start_f / fps_stim\n",
    "    end   = end_f   / fps_stim\n",
    "    ax.axvspan(start, end, alpha=0.3)  # avoid hardcoding a color unless you want to\n"
   ],
   "id": "4c73663c614217ef",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plotting",
   "id": "17fed5cbbe3cbbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:45:29.197358Z",
     "start_time": "2025-11-18T16:45:28.153794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# select parameters including sorting mode, stimuli order, and windows\n",
    "# sort deltaF_F base on max_intensity, correlation, kmeans, \"pca\", \"hier\",  or \"unsorted\"\n",
    "# --- choose stimulus-aligned windows ---\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, leaves_list\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist\n",
    "# --- choose neuron sorting ---\n",
    "window_pre = 5  # seconds before stimulus\n",
    "window_post = 17  # seconds after stimulus\n",
    "\n",
    "\n",
    "# <-- change to: max_intensity, correlation, kmeans, \"pca\", \"hier\",  or \"unsorted\"\n",
    "sort_mode = \"max_intensity\"\n",
    "\n",
    "# define stimuli order based on experiment\n",
    "stimuli_ordered_A = ['LLB', 'FLB', 'RLB' , 'FRB','FL1', 'FL2', 'FL3', 'FR1', 'FR2', 'FR3']  # Order of\n",
    "stimuli_ordered_B = ['LB','RB','RR1','RR2','RR3','RL1','RL2','RL3','RLR1','RLR2' ]\n",
    "\n",
    "if experiment_name == 'Exp_2_rocking_1':\n",
    "    stimuli_ordered = stimuli_ordered_B\n",
    "else:\n",
    "    stimuli_ordered = stimuli_ordered_A\n",
    "\n",
    "# (a) Max intensity (peak Î”F/F per neuron)\n",
    "max_per_neuron   = np.nanmax(deltaF_F, axis=0)         # (neurons,)\n",
    "maxint_sorted_idx = np.argsort(-max_per_neuron)\n",
    "\n",
    "# (b) PCA (PC1 desc) over neurons\n",
    "scores    = PCA(n_components=3).fit_transform(deltaF_F.T )  # (neurons, 3)\n",
    "PCA_order = np.argsort(-scores[:, 0])\n",
    "\n",
    "# (c) KMeans over neurons\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(deltaF_F.T )\n",
    "kmeans_sorted_idx = np.argsort(kmeans.labels_)  # group by label\n",
    "\n",
    "# (d) Hierarchical (Ward) over neurons\n",
    "Z_hier = linkage(deltaF_F.T , method='ward')\n",
    "clusters = fcluster(Z_hier, t=5, criterion='maxclust')\n",
    "hier_sorted_idx = np.argsort(clusters)\n",
    "\n",
    "# (e) Correlation sort on the **averaged chunks** (neurons x time)\n",
    "dist = pdist(deltaF_F.T, metric='correlation')\n",
    "Z_corr = linkage(dist, method='average')\n",
    "corravg_sorted_idx = leaves_list(Z_corr)\n",
    "\n",
    "\n",
    "n_neurons = deltaF_F.shape[1]\n",
    "\n",
    "def _validate_order(idx, name):\n",
    "    if idx is None:\n",
    "        raise ValueError(f\"{name} is not defined but sort_mode='{name}' was selected.\")\n",
    "    if len(idx) != n_neurons:\n",
    "        raise ValueError(f\"{name} length ({len(idx)}) != number of neurons ({n_neurons}).\")\n",
    "    return idx\n",
    "\n",
    "if sort_mode == \"kmeans\":\n",
    "    neuron_order = _validate_order(kmeans_sorted_idx, \"kmeans_sorted_idx\")\n",
    "elif sort_mode == \"pca\":\n",
    "    neuron_order = _validate_order(PCA_order, \"PCA_order\")\n",
    "elif sort_mode == \"hier\":\n",
    "    neuron_order = _validate_order(hier_sorted_idx, \"hier_sorted_idx\")\n",
    "elif sort_mode == \"max_intensity\":\n",
    "    neuron_order = _validate_order(maxint_sorted_idx, \"maxint_sorted_idx\")\n",
    "elif sort_mode == \"correlation\":\n",
    "    neuron_order = _validate_order(corravg_sorted_idx, \"corravg_sorted_idx\")\n",
    "elif sort_mode == \"unsorted\":\n",
    "    neuron_order = None\n",
    "else:\n",
    "    raise ValueError(\"sort_mode must be one of: 'kmeans', 'pca', 'hier', 'max_intensity', 'unsorted'\")\n",
    "print(stimuli_ordered)"
   ],
   "id": "5d32a60928227cd9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suribear\\AppData\\Local\\anaconda3\\envs\\neuro-group\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LLB', 'FLB', 'RLB', 'FRB', 'FL1', 'FL2', 'FL3', 'FR1', 'FR2', 'FR3']\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:45:35.689025Z",
     "start_time": "2025-11-18T16:45:35.299300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gruped chunks ordered by stimulus type, sorted by selected method\n",
    "\n",
    "# 1) Build chunks\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=deltaF_F,\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=False,\n",
    ")\n",
    "\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "\n",
    "# 2) Plot raster\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "im = plott.raster_with_stimuli(\n",
    "    ax=ax,\n",
    "    deltaF_F=chunked_data.T,   # (time, neurons)\n",
    "    fps=fps_2p,\n",
    "    fish_id=fish_id,\n",
    "    neuron_order=neuron_order, # provided by your sort selector\n",
    "    title_suffix=f\"ordered by stimulus type | sort={sort_mode}\",\n",
    "    max=0.2\n",
    ")\n",
    "\n",
    "# 3) Movement start lines â€” use style based on each chunk's stimulus label\n",
    "move_styles = [stimuli_linestyles.get(name, '-') for name in stim_labels]\n",
    "for pos, color, ls in zip(move_starts, move_colors, move_styles):\n",
    "    ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.0)\n",
    "\n",
    "ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "\n",
    "# 4) Legend that matches color + linestyle\n",
    "legend_handles = []\n",
    "for stim_name, color in stimuli_colors.items():\n",
    "    ls = stimuli_linestyles.get(stim_name, '-')\n",
    "    (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=2)\n",
    "    legend_handles.append(line)\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Movement onset\\nacross stimuli\",\n",
    "    bbox_to_anchor=(1.15, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# 5) Colorbar + layout\n",
    "fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "############################ AVERAGE\n",
    "\n",
    "# averaged chunked_data shape: (neurons, time) sorted by stimulus type and by pearson correlation\n",
    "# ---- 1) Extract chunks from the full dfof, averaged across repeats ----\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=deltaF_F,                 # (frames, neurons)\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=True\n",
    ")\n",
    "\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "\n",
    "# chunked_data shape: (neurons, time)  âœ…\n",
    "\n",
    "# ---- 2) Compute distances: 1 - Pearson correlation across the (averaged) chunked time series ----\n",
    "dist = pdist(chunked_data, metric='correlation')  # rows = neurons, columns = time (averaged)\n",
    "Z = linkage(dist, method='average')\n",
    "sorted_indices = leaves_list(Z)\n",
    "\n",
    "# ---- 3) Plot the correlation-sorted raster ----\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "im = plott.raster_with_stimuli(\n",
    "    ax=ax,\n",
    "    deltaF_F=chunked_data.T,    # (time, neurons)\n",
    "    fps=fps_2p,\n",
    "    fish_id=fish_id,\n",
    "    neuron_order=sorted_indices,\n",
    "    title_suffix='Average across trials â€¢ sorted by Pearson correlation',\n",
    "    min=0.009,\n",
    "    max=0.2\n",
    ")\n",
    "\n",
    "\n",
    "# 3) âžœ Overlay movement start lines using per-stim linestyle\n",
    "for pos, stim_name in zip(move_starts, stim_labels):\n",
    "    color = stimuli_colors.get(stim_name, 'black')\n",
    "    ls    = stimuli_linestyles.get(stim_name, '-')   # default solid if not specified\n",
    "    ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.5)\n",
    "\n",
    "# 4) âžœ Legend that reflects both color and linestyle\n",
    "legend_handles = []\n",
    "for stim_name in stimuli_ordered:\n",
    "    if stim_name in stimuli_colors:\n",
    "        color = stimuli_colors[stim_name]\n",
    "        ls    = stimuli_linestyles.get(stim_name, '-')  # same default\n",
    "        (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=1.5)\n",
    "        legend_handles.append(line)\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Movement onset \\n across stimuli\",\n",
    "    bbox_to_anchor=(1.2, 1),\n",
    "    loc='upper left',\n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "\n",
    "# 5) Colorbar + layout ... [unchanged]\n",
    "fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()\n"
   ],
   "id": "18856fd1888d1acb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d549096aaff8bb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:47:03.511153Z",
     "start_time": "2025-11-18T16:47:02.558730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## saved plot of gruped chunks ordered by stimulus type, sorted by selected method\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"  # or \"1\"\n",
    "\n",
    "# ----- pick a short prefix like \"L433_f03\" from \"L433_f03_Exp_1_flickering\"\n",
    "# prefix = \"_\".join(fish.split(\"_\")[:2])\n",
    "\n",
    "# ----- ensure output dir exists\n",
    "# plots_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== 1) Build chunks (averaged across repeats) once =====\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=deltaF_F,                 # (frames, neurons)\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=False\n",
    ")\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "# chunked_data: (neurons, time)\n",
    "\n",
    "# ===== 2) Precompute neuron orders for each sort mode (on full dfof unless noted) =====\n",
    "#deltaF_F = dfof  # (frames, neurons)\n",
    "\n",
    "# (a) Max intensity (peak Î”F/F per neuron)\n",
    "max_per_neuron   = np.nanmax(chunked_data.T, axis=0)         # (neurons,)\n",
    "maxint_sorted_idx = np.argsort(-max_per_neuron)\n",
    "\n",
    "# (b) PCA (PC1 desc) over neurons\n",
    "scores    = PCA(n_components=3).fit_transform(chunked_data)  # (neurons, 3)\n",
    "PCA_order = np.argsort(-scores[:, 0])\n",
    "\n",
    "# (c) KMeans over neurons\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(chunked_data)\n",
    "kmeans_sorted_idx = np.argsort(kmeans.labels_)  # group by label\n",
    "\n",
    "# (d) Hierarchical (Ward) over neurons\n",
    "Z_hier = linkage(chunked_data, method='ward')\n",
    "clusters = fcluster(Z_hier, t=5, criterion='maxclust')\n",
    "hier_sorted_idx = np.argsort(clusters)\n",
    "\n",
    "# (e) Correlation sort on the **averaged chunks** (neurons x time)\n",
    "dist = pdist(chunked_data, metric='correlation')\n",
    "Z_corr = linkage(dist, method='average')\n",
    "corravg_sorted_idx = leaves_list(Z_corr)\n",
    "\n",
    "# Map from mode -> (index array or None, label suffix)\n",
    "sorters = {\n",
    "    \"unsorted\":        (None,                   \"unsorted\"),\n",
    "    \"max_intensity\":   (maxint_sorted_idx,      \"max_intensity\"),\n",
    "    \"pca\":             (PCA_order,              \"pca\"),\n",
    "    \"kmeans\":          (kmeans_sorted_idx,      \"kmeans\"),\n",
    "    \"hier\":            (hier_sorted_idx,        \"hier\"),\n",
    "    \"corravg\":         (corravg_sorted_idx,     \"corravg\"),  # correlation on averaged chunks\n",
    "}\n",
    "\n",
    "\n",
    "def _validate_order(idx, n_neurons, name):\n",
    "    if idx is None:\n",
    "        return None\n",
    "    if len(idx) != n_neurons:\n",
    "        raise ValueError(f\"{name} length ({len(idx)}) != number of neurons ({n_neurons}).\")\n",
    "    return idx\n",
    "\n",
    "# ===== 3) Plot once per sort mode (use chunked_data for raster) =====\n",
    "for mode, (idx, tag) in sorters.items():\n",
    "    neuron_order = _validate_order(idx, chunked_data.shape[0], name=mode)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    im = plott.raster_with_stimuli(\n",
    "        ax=ax,\n",
    "        deltaF_F=chunked_data.T,            # (time, neurons)\n",
    "        fps=fps_2p,\n",
    "        fish_id=fish_id,\n",
    "        neuron_order=neuron_order,          # None = original order\n",
    "        title_suffix=f\"ordered by stimulus type | sort={tag}\",\n",
    "        min=0.009,\n",
    "        max=0.2\n",
    "    )\n",
    "\n",
    "    # Movement onset lines with per-stim color + linestyle\n",
    "    for pos, stim_name in zip(move_starts, stim_labels):\n",
    "        color = stimuli_colors.get(stim_name, 'black')\n",
    "        ls    = stimuli_linestyles.get(stim_name, '-')  # default solid\n",
    "        ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.8)\n",
    "\n",
    "    # Legend (color + linestyle)\n",
    "    legend_handles = []\n",
    "    for stim_name in stimuli_ordered:\n",
    "        if stim_name in stimuli_colors:\n",
    "            color = stimuli_colors[stim_name]\n",
    "            ls    = stimuli_linestyles.get(stim_name, '-')\n",
    "            (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=1.5)\n",
    "            legend_handles.append(line)\n",
    "\n",
    "    leg = ax.legend(\n",
    "        handles=legend_handles, title=\"Movement onset\\nacross stimuli\",\n",
    "        bbox_to_anchor=(1.2, 1), loc='upper left',\n",
    "        borderaxespad=0, frameon=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "    fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "\n",
    "    # Save\n",
    "    out_png = plots_path / f\"{prefix}_grouped_dfof_sorted_by_{tag}.png\"\n",
    "    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"âœ… Saved:\", *[f\"{prefix}_grouped_dfof_sorted_by_{tag}.png\" for _, (_, tag) in sorters.items()], sep=\"\\n- \")"
   ],
   "id": "af6d1a0a331a1518",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suribear\\AppData\\Local\\anaconda3\\envs\\neuro-group\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plots_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 114\u001B[39m\n\u001B[32m    111\u001B[39m plt.subplots_adjust(right=\u001B[32m0.85\u001B[39m)\n\u001B[32m    113\u001B[39m \u001B[38;5;66;03m# Save\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m out_png = plots_path / \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_grouped_dfof_sorted_by_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtag\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.png\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    115\u001B[39m fig.savefig(out_png, dpi=\u001B[32m600\u001B[39m, bbox_inches=\u001B[33m\"\u001B[39m\u001B[33mtight\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    116\u001B[39m plt.close(fig)\n",
      "\u001B[31mNameError\u001B[39m: name 'plots_path' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:49:23.410235Z",
     "start_time": "2025-11-18T16:49:22.927952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Purpose.\n",
    "# Generate experiment-level Î”F/F rasters aligned to stimulus onsets, averaged across repeats, and saved once per sorting strategy (unsorted, max intensity, PCA, KMeans, hierarchical, and correlation on averaged responses).\n",
    "# save all these plots\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"  # or \"1\"\n",
    "\n",
    "\n",
    "# ----- ensure output dir exists\n",
    "paths['plots_path'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== 1) Build chunks (averaged across repeats) once =====\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=deltaF_F,  # (frames, neurons)\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=True\n",
    ")\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "# chunked_data: (neurons, time)\n",
    "\n",
    "# ===== 2) Precompute neuron orders for each sort mode (on full dfof unless noted) =====\n",
    "# deltaF_F = dfof  # (frames, neurons)\n",
    "\n",
    "# (a) Max intensity (peak Î”F/F per neuron)\n",
    "max_per_neuron = np.nanmax(chunked_data.T, axis=0)  # (neurons,)\n",
    "maxint_sorted_idx = np.argsort(-max_per_neuron)\n",
    "\n",
    "# (b) PCA (PC1 desc) over neurons\n",
    "scores = PCA(n_components=3).fit_transform(chunked_data)  # (neurons, 3)\n",
    "PCA_order = np.argsort(-scores[:, 0])\n",
    "\n",
    "# (c) KMeans over neurons\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(chunked_data)\n",
    "kmeans_sorted_idx = np.argsort(kmeans.labels_)  # group by label\n",
    "\n",
    "# (d) Hierarchical (Ward) over neurons\n",
    "Z_hier = linkage(chunked_data, method='ward')\n",
    "clusters = fcluster(Z_hier, t=5, criterion='maxclust')\n",
    "hier_sorted_idx = np.argsort(clusters)\n",
    "\n",
    "# (e) Correlation sort on the **averaged chunks** (neurons x time)\n",
    "dist = pdist(chunked_data, metric='correlation')\n",
    "Z_corr = linkage(dist, method='average')\n",
    "corravg_sorted_idx = leaves_list(Z_corr)\n",
    "\n",
    "# Map from mode -> (index array or None, label suffix)\n",
    "sorters = {\n",
    "    \"unsorted\": (None, \"unsorted\"),\n",
    "    \"max_intensity\": (maxint_sorted_idx, \"max_intensity\"),\n",
    "    \"pca\": (PCA_order, \"pca\"),\n",
    "    \"kmeans\": (kmeans_sorted_idx, \"kmeans\"),\n",
    "    \"hier\": (hier_sorted_idx, \"hier\"),\n",
    "    \"corravg\": (corravg_sorted_idx, \"corravg\"),  # correlation on averaged chunks\n",
    "}\n",
    "\n",
    "\n",
    "def _validate_order(idx, n_neurons, name):\n",
    "    if idx is None:\n",
    "        return None\n",
    "    if len(idx) != n_neurons:\n",
    "        raise ValueError(f\"{name} length ({len(idx)}) != number of neurons ({n_neurons}).\")\n",
    "    return idx\n",
    "\n",
    "\n",
    "# ===== 3) Plot once per sort mode (use chunked_data for raster) =====\n",
    "for mode, (idx, tag) in sorters.items():\n",
    "    neuron_order = _validate_order(idx, chunked_data.shape[0], name=mode)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    im = plott.raster_with_stimuli(\n",
    "        ax=ax,\n",
    "        deltaF_F=chunked_data.T,  # (time, neurons)\n",
    "        fps=fps_2p,\n",
    "        fish_id=fish_id,\n",
    "        neuron_order=neuron_order,  # None = original order\n",
    "        title_suffix=f\"average across trials | sort={tag}\",\n",
    "        min=0.009,\n",
    "        max=0.2\n",
    "    )\n",
    "\n",
    "    # Movement onset lines with per-stim color + linestyle\n",
    "    for pos, stim_name in zip(move_starts, stim_labels):\n",
    "        color = stimuli_colors.get(stim_name, 'black')\n",
    "        ls = stimuli_linestyles.get(stim_name, '-')  # default solid\n",
    "        ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.8)\n",
    "\n",
    "    # Legend (color + linestyle)\n",
    "    legend_handles = []\n",
    "    for stim_name in stimuli_ordered:\n",
    "        if stim_name in stimuli_colors:\n",
    "            color = stimuli_colors[stim_name]\n",
    "            ls = stimuli_linestyles.get(stim_name, '-')\n",
    "            (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=1.5)\n",
    "            legend_handles.append(line)\n",
    "\n",
    "    leg = ax.legend(\n",
    "        handles=legend_handles, title=\"Movement onset\\nacross stimuli\",\n",
    "        bbox_to_anchor=(1.2, 1), loc='upper left',\n",
    "        borderaxespad=0, frameon=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "    fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "\n",
    "    # Save\n",
    "    out_png = plots_path / f\"{prefix}_average_dfof_sorted_by_{tag}.png\"\n",
    "    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"âœ… Saved:\", *[f\"{prefix}_average_dfof_sorted_by_{tag}.png\" for _, (_, tag) in sorters.items()], sep=\"\\n- \")\n"
   ],
   "id": "c993c403bdce523c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suribear\\AppData\\Local\\anaconda3\\envs\\neuro-group\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plots_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 115\u001B[39m\n\u001B[32m    112\u001B[39m plt.subplots_adjust(right=\u001B[32m0.85\u001B[39m)\n\u001B[32m    114\u001B[39m \u001B[38;5;66;03m# Save\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m out_png = plots_path / \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_average_dfof_sorted_by_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtag\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.png\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    116\u001B[39m fig.savefig(out_png, dpi=\u001B[32m600\u001B[39m, bbox_inches=\u001B[33m\"\u001B[39m\u001B[33mtight\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    117\u001B[39m plt.close(fig)\n",
      "\u001B[31mNameError\u001B[39m: name 'plots_path' is not defined"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20fbee878e3f80f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:51:46.181901Z",
     "start_time": "2025-11-18T16:49:38.591664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.significant_traces import compute_noise_model_romano_fast_modular, plot_dff_and_raster\n",
    "\n",
    "FPS_DEFAULT = 2.0\n",
    "TAUDECAY_DEFAULT = 6.0\n",
    "\n",
    "ST_N_BINS       = 2000\n",
    "ST_K_NEIGHBORS  = 100\n",
    "ST_CONF_CUTOFF  = 95\n",
    "ST_PLOT_ODDS    = False\n",
    "ST_VMAX_DFF     = 0.15\n",
    "\n",
    "(mapOfOdds,\n",
    "         deltaF_center,\n",
    "         density_data,\n",
    "         density_noise,\n",
    "         xev, yev,\n",
    "         raster,\n",
    "         mapOfOddsJoint) = compute_noise_model_romano_fast_modular(\n",
    "             deltaF_F,\n",
    "             n_bins=ST_N_BINS,\n",
    "             k_neighbors=ST_K_NEIGHBORS,\n",
    "             confCutOff=ST_CONF_CUTOFF,\n",
    "             plot_odds=ST_PLOT_ODDS,\n",
    "             fps=FPS_DEFAULT,\n",
    "             tauDecay=TAUDECAY_DEFAULT,\n",
    "        )\n"
   ],
   "id": "426e3aa6f4250414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noise Fit] Used fallback on 0 out of 641 ROIs (0.0%)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:51:59.039164Z",
     "start_time": "2025-11-18T16:51:58.921462Z"
    }
   },
   "cell_type": "code",
   "source": "print(deltaF_F.shape, raster.shape)",
   "id": "618aaf93a9669d8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3340, 641) (3340, 641)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T16:48:26.994742Z",
     "start_time": "2025-11-13T16:48:26.796862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sort_idx = plot_dff_and_raster(deltaF_center[:,1:100], raster[:,1:100], fps=2.0, vmax_dff=0.3)\n",
    "\n",
    "# Sanity check before pdist\n",
    "n_neurons =raster.shape[1] #  frames x nueroso\n",
    "nan_mask = ~np.isfinite(raster).all(axis=0)\n",
    "zero_var_mask = np.nanstd(raster, axis=0) == 0\n",
    "\n",
    "print(\"Neurons with any NaN:\", np.where(nan_mask)[0])\n",
    "print(\"Neurons with zero variance:\", np.where(zero_var_mask)[0])\n",
    "print(\"Total bad neurons:\", np.sum(nan_mask | zero_var_mask), \"out of\", n_neurons)"
   ],
   "id": "c3948b94edc55a0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons with any NaN: []\n",
      "Neurons with zero variance: [74]\n",
      "Total bad neurons: 1 out of 641\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:26:38.662445Z",
     "start_time": "2025-11-13T14:26:38.371097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#raster: (frames, neurons)\n",
    "n_neurons = raster.shape[1]  # frames x neurons\n",
    "nan_mask = ~np.isfinite(raster).all(axis=0)         # per neuron\n",
    "zero_var_mask = np.nanstd(raster, axis=0) == 0      # per neuron\n",
    "\n",
    "print(\"Neurons with any NaN:\", np.where(nan_mask)[0])\n",
    "print(\"Neurons with zero variance:\", np.where(zero_var_mask)[0])\n",
    "print(\"Total bad neurons:\", np.sum(nan_mask | zero_var_mask), \"out of\", n_neurons)"
   ],
   "id": "85ddc52b56fb40f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons with any NaN: []\n",
      "Neurons with zero variance: [ 74  83  87  91 112 117 122 137 154 262 272 276 278 379 383 436 465 468\n",
      " 473 539 568 570 611 614]\n",
      "Total bad neurons: 24 out of 641\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:31:21.196729Z",
     "start_time": "2025-11-13T14:31:12.921369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# raster: (frames, neurons)\n",
    "n_neurons = raster.shape[1]\n",
    "\n",
    "# 1) Find bad neurons\n",
    "nan_mask = ~np.isfinite(raster).all(axis=0)        # neurons with any NaN/inf\n",
    "zero_var_mask = np.nanstd(raster, axis=0) == 0     # neurons with flat trace\n",
    "\n",
    "bad_mask = nan_mask | zero_var_mask\n",
    "good_mask = ~bad_mask\n",
    "\n",
    "print(\"Dropped\", bad_mask.sum(), \"neurons out of\", n_neurons)\n",
    "\n",
    "# 2) Keep only good neurons\n",
    "raster_clean = raster[:, good_mask]\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"  # or \"1\"\n",
    "\n",
    "# ----- pick a short prefix like \"L433_f03\" from \"L433_f03_Exp_1_flickering\"\n",
    "prefix = \"_\".join(fish.split(\"_\")[:2])\n",
    "\n",
    "# ----- ensure output dir exists\n",
    "plots_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== 1) Build chunks (averaged across repeats) once =====\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=raster_clean,  # (frames, neurons)\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=True\n",
    ")\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "# chunked_data: (neurons, time)\n",
    "\n",
    "# ===== 2) Precompute neuron orders for each sort mode (on full dfof unless noted) =====\n",
    "# deltaF_F = dfof  # (frames, neurons)\n",
    "\n",
    "# (a) Max intensity (peak Î”F/F per neuron)\n",
    "max_per_neuron = np.nanmax(chunked_data.T, axis=0)  # (neurons,)\n",
    "maxint_sorted_idx = np.argsort(-max_per_neuron)\n",
    "\n",
    "# (b) PCA (PC1 desc) over neurons\n",
    "scores = PCA(n_components=3).fit_transform(chunked_data)  # (neurons, 3)\n",
    "PCA_order = np.argsort(-scores[:, 0])\n",
    "\n",
    "# (c) KMeans over neurons\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(chunked_data)\n",
    "kmeans_sorted_idx = np.argsort(kmeans.labels_)  # group by label\n",
    "\n",
    "# (d) Hierarchical (Ward) over neurons\n",
    "Z_hier = linkage(chunked_data, method='ward')\n",
    "clusters = fcluster(Z_hier, t=5, criterion='maxclust')\n",
    "hier_sorted_idx = np.argsort(clusters)\n",
    "\n",
    "# (e) Correlation sort on the **averaged chunks** (neurons x time)\n",
    "dist = pdist(chunked_data, metric='correlation')\n",
    "Z_corr = linkage(dist, method='average')\n",
    "corravg_sorted_idx = leaves_list(Z_corr)\n",
    "\n",
    "# Map from mode -> (index array or None, label suffix)\n",
    "sorters = {\n",
    "    \"unsorted\": (None, \"unsorted\"),\n",
    "    \"max_intensity\": (maxint_sorted_idx, \"max_intensity\"),\n",
    "    \"pca\": (PCA_order, \"pca\"),\n",
    "    \"kmeans\": (kmeans_sorted_idx, \"kmeans\"),\n",
    "    \"hier\": (hier_sorted_idx, \"hier\"),\n",
    "    \"corravg\": (corravg_sorted_idx, \"corravg\"),  # correlation on averaged chunks\n",
    "}\n",
    "\n",
    "\n",
    "def _validate_order(idx, n_neurons, name):\n",
    "    if idx is None:\n",
    "        return None\n",
    "    if len(idx) != n_neurons:\n",
    "        raise ValueError(f\"{name} length ({len(idx)}) != number of neurons ({n_neurons}).\")\n",
    "    return idx\n",
    "\n",
    "\n",
    "# ===== 3) Plot once per sort mode (use chunked_data for raster) =====\n",
    "for mode, (idx, tag) in sorters.items():\n",
    "    neuron_order = _validate_order(idx, chunked_data.shape[0], name=mode)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    im = plott.raster_with_stimuli(\n",
    "        ax=ax,\n",
    "        deltaF_F=chunked_data.T,  # (time, neurons)\n",
    "        fps=fps_2p,\n",
    "        fish_id=fish_id,\n",
    "        neuron_order=neuron_order,  # None = original order\n",
    "        title_suffix=f\"average across trials | sort={tag}\",\n",
    "        min=0.009,\n",
    "        max=1\n",
    "    )\n",
    "\n",
    "    # Movement onset lines with per-stim color + linestyle\n",
    "    for pos, stim_name in zip(move_starts, stim_labels):\n",
    "        color = stimuli_colors.get(stim_name, 'black')\n",
    "        ls = stimuli_linestyles.get(stim_name, '-')  # default solid\n",
    "        ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.8)\n",
    "\n",
    "    # Legend (color + linestyle)\n",
    "    legend_handles = []\n",
    "    for stim_name in stimuli_ordered:\n",
    "        if stim_name in stimuli_colors:\n",
    "            color = stimuli_colors[stim_name]\n",
    "            ls = stimuli_linestyles.get(stim_name, '-')\n",
    "            (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=1.5)\n",
    "            legend_handles.append(line)\n",
    "\n",
    "    leg = ax.legend(\n",
    "        handles=legend_handles, title=\"Movement onset\\nacross stimuli\",\n",
    "        bbox_to_anchor=(1.2, 1), loc='upper left',\n",
    "        borderaxespad=0, frameon=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "    fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "\n",
    "    # Save\n",
    "    out_png = plots_path / f\"{prefix}_average_raster_dfof_sorted_by_{tag}.png\"\n",
    "    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"âœ… Saved:\", *[f\"{prefix}_average_raster_sorted_by_{tag}.png\" for _, (_, tag) in sorters.items()], sep=\"\\n- \")\n"
   ],
   "id": "c2f03fca05d70266",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 24 neurons out of 641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suribear\\AppData\\Local\\anaconda3\\envs\\neuro-group\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved:\n",
      "- L433_f02_average_raster_sorted_by_unsorted.png\n",
      "- L433_f02_average_raster_sorted_by_max_intensity.png\n",
      "- L433_f02_average_raster_sorted_by_pca.png\n",
      "- L433_f02_average_raster_sorted_by_kmeans.png\n",
      "- L433_f02_average_raster_sorted_by_hier.png\n",
      "- L433_f02_average_raster_sorted_by_corravg.png\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:51:15.736024Z",
     "start_time": "2025-11-13T14:51:15.338256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gruped chunks ordered by stimulus type, sorted by selected method\n",
    "\n",
    "# raster: (frames, neurons)\n",
    "n_neurons = raster.shape[1]\n",
    "\n",
    "# 1) Find bad neurons\n",
    "nan_mask = ~np.isfinite(raster).all(axis=0)        # neurons with any NaN/inf\n",
    "zero_var_mask = np.nanstd(raster, axis=0) == 0     # neurons with flat trace\n",
    "\n",
    "bad_mask = nan_mask | zero_var_mask\n",
    "good_mask = ~bad_mask\n",
    "\n",
    "print(\"Dropped\", bad_mask.sum(), \"neurons out of\", n_neurons)\n",
    "\n",
    "# 2) Keep only good neurons\n",
    "raster_clean = raster[:, good_mask]\n",
    "\n",
    "# 1) Build chunks\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=raster,\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=False,\n",
    ")\n",
    "\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "\n",
    "# 2) Plot raster\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "im = plott.raster_with_stimuli(\n",
    "    ax=ax,\n",
    "    deltaF_F=chunked_data.T,   # (time, neurons)\n",
    "    fps=fps_2p,\n",
    "    fish_id=fish_id,\n",
    "    neuron_order=neuron_order, # provided by your sort selector\n",
    "    title_suffix=f\"ordered by stimulus type | sort={sort_mode}\",\n",
    "    max=0.2\n",
    ")\n",
    "\n",
    "# 3) Movement start lines â€” use style based on each chunk's stimulus label\n",
    "move_styles = [stimuli_linestyles.get(name, '-') for name in stim_labels]\n",
    "for pos, color, ls in zip(move_starts, move_colors, move_styles):\n",
    "    ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.0)\n",
    "\n",
    "ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "\n",
    "# 4) Legend that matches color + linestyle\n",
    "legend_handles = []\n",
    "for stim_name, color in stimuli_colors.items():\n",
    "    ls = stimuli_linestyles.get(stim_name, '-')\n",
    "    (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=2)\n",
    "    legend_handles.append(line)\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Movement onset\\nacross stimuli\",\n",
    "    bbox_to_anchor=(1.15, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# 5) Colorbar + layout\n",
    "fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 1) Build chunks\n",
    "chunked_data, trial_starts, move_starts, move_colors, stim_labels = st.extract_stimulus_chunks(\n",
    "    deltaF_F=deltaF_F,\n",
    "    exp_log=exp_log,\n",
    "    stimuli_durations=stimuli_durations,\n",
    "    stimuli_colors=stimuli_colors,\n",
    "    fps=fps_2p,\n",
    "    stimuli_ordered=stimuli_ordered,\n",
    "    window_pre=window_pre,\n",
    "    window_post=window_post,\n",
    "    average_across_repeats=False,\n",
    ")\n",
    "\n",
    "if chunked_data is None or chunked_data.size == 0:\n",
    "    raise ValueError(\"No stimulus chunks were extracted. Check exp_log, stimuli_ordered, and windows.\")\n",
    "\n",
    "# 2) Plot raster\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "im = plott.raster_with_stimuli(\n",
    "    ax=ax,\n",
    "    deltaF_F=chunked_data.T,   # (time, neurons)\n",
    "    fps=fps_2p,\n",
    "    fish_id=fish_id,\n",
    "    neuron_order=neuron_order, # provided by your sort selector\n",
    "    title_suffix=f\"ordered by stimulus type | sort={sort_mode}\",\n",
    "    max=0.3\n",
    ")\n",
    "\n",
    "# 3) Movement start lines â€” use style based on each chunk's stimulus label\n",
    "move_styles = [stimuli_linestyles.get(name, '-') for name in stim_labels]\n",
    "for pos, color, ls in zip(move_starts, move_colors, move_styles):\n",
    "    ax.axvline(pos / fps_2p, color=color, linestyle=ls, alpha=0.9, linewidth=1.0)\n",
    "\n",
    "ax.set_xlabel(\"Chunks aligned to stimulus onset (s)\")\n",
    "\n",
    "# 4) Legend that matches color + linestyle\n",
    "legend_handles = []\n",
    "for stim_name, color in stimuli_colors.items():\n",
    "    ls = stimuli_linestyles.get(stim_name, '-')\n",
    "    (line,) = ax.plot([], [], color=color, linestyle=ls, label=stim_name, linewidth=2)\n",
    "    legend_handles.append(line)\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Movement onset\\nacross stimuli\",\n",
    "    bbox_to_anchor=(1.15, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# 5) Colorbar + layout\n",
    "fig.colorbar(im, ax=ax, label=\"Î”F/F\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "8966ce358e0017d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 24 neurons out of 641\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
